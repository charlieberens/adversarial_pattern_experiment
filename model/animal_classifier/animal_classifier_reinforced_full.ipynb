{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs for new environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install tensorflow\n",
    "# !{sys.executable} -m pip install matplotlib\n",
    "# !{sys.executable} -m pip install numpy\n",
    "# !{sys.executable} -m pip install pillow\n",
    "# !{sys.executable} -m pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import math\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim = 256 # eventual width/height of images\n",
    "input_shape = (image_dim, image_dim, 3) #(width, height, RGB)\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 32\n",
    "learning_rate = .001\n",
    "\n",
    "train_dir = 'dataset/train'\n",
    "validate_dir = 'dataset/validate'\n",
    "\n",
    "save_dir = 'models/reinforced_full'\n",
    "file_name_base = 'reinforced_full'\n",
    "\n",
    "base_log_dir = '/logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True) # Reinforcements for training dataset\n",
    "\n",
    "validate = ImageDataGenerator(rescale=1./255) # Reinforcements for validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#loads the datasets\n",
    "train_dataset = train.flow_from_directory(train_dir, target_size=(image_dim, image_dim), class_mode='categorical') \n",
    "validate_dataset = train.flow_from_directory(validate_dir, target_size=(image_dim, image_dim), class_mode='categorical')\n",
    "\n",
    "# tf.keras.preprocessing.image_dataset_from_directory - this can be used for no reinforcement\n",
    "\n",
    "n_train = train_dataset.samples # number of images in training dataset\n",
    "n_validate = validate_dataset.samples # number of images in validation dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_keys = list(train_dataset.class_indices.keys())\n",
    "n_classes = len(class_keys)\n",
    "\n",
    "# defines the layers of the cnn\n",
    "model = tf.keras.models.Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(n_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = base_log_dir + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Save the initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 76s 1s/step - loss: 2.3031 - accuracy: 0.0985\n",
      "INFO:tensorflow:Assets written to: models/reinforced_full/reinforced_full_0\\assets\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(validate_dataset, batch_size=256)\n",
    "model.save(save_dir + '/' + file_name_base + '_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "250/250 [==============================] - 887s 4s/step - loss: 1.3661 - accuracy: 0.5288 - val_loss: 1.5615 - val_accuracy: 0.4677\n",
      "Epoch 2/15\n",
      "250/250 [==============================] - 754s 3s/step - loss: 1.3215 - accuracy: 0.5471 - val_loss: 1.4628 - val_accuracy: 0.4919\n",
      "Epoch 3/15\n",
      "250/250 [==============================] - 746s 3s/step - loss: 1.2761 - accuracy: 0.5686 - val_loss: 1.4298 - val_accuracy: 0.5106\n",
      "Epoch 4/15\n",
      "250/250 [==============================] - 747s 3s/step - loss: 1.2335 - accuracy: 0.5781 - val_loss: 1.4329 - val_accuracy: 0.5181\n",
      "Epoch 5/15\n",
      "250/250 [==============================] - 746s 3s/step - loss: 1.2089 - accuracy: 0.5893 - val_loss: 1.3874 - val_accuracy: 0.5227\n",
      "Epoch 6/15\n",
      "191/250 [=====================>........] - ETA: 2:43 - loss: 1.1663 - accuracy: 0.6113"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset,\n",
    "                    steps_per_epoch=math.floor(n_train/batch_size),\n",
    "                    validation_data=validate_dataset,\n",
    "                    validation_steps=math.floor(n_validate/batch_size),\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/reinforced_full/reinforced_full_15\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(save_dir + '/' + file_name_base + '_15')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73b88dd79e00e0f4f57583c826c7adc853d853881b61c8cf34662a4ee9c223e3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
