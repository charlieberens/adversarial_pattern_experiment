{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs for new environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install tensorflow\n",
    "# !{sys.executable} -m pip install matplotlib\n",
    "# !{sys.executable} -m pip install numpy\n",
    "# !{sys.executable} -m pip install pillow\n",
    "# !{sys.executable} -m pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import math\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim = 256 # eventual width/height of images\n",
    "input_shape = (image_dim, image_dim, 3) #(width, height, RGB)\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "learning_rate = .001\n",
    "\n",
    "train_dir = 'dataset/train'\n",
    "validate_dir = 'dataset/validate'\n",
    "\n",
    "base_log_dir = '/logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copied Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for the initial validation step. Feel free to ignore.\n",
    "\n",
    "def get_class_labels(dir):\n",
    "    \"\"\"\n",
    "    Gets the name of each sub-directory in the given directory.\n",
    "    \n",
    "    dir: Directory to search.\n",
    "    return: An array of the names of the sub-directories in dir.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all sub-directories in this directory\n",
    "    classes = os.listdir(dir)\n",
    "    \n",
    "    return classes\n",
    "    \n",
    "def get_class_images(classes, dir):\n",
    "    \"\"\"\n",
    "    Gets the paths of all images in each directory.\n",
    "    \n",
    "    classes: Name of each class.\n",
    "    dir: Directory to search.\n",
    "    return: A 2d array of paths organized by class name.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an array to hold the image paths of each class\n",
    "    class_paths = []\n",
    "\n",
    "    # Create image paths of each class\n",
    "    for label in classes:\n",
    "        \n",
    "        # Create an array to hold the image paths of this class (label)\n",
    "        image_paths = np.array([])\n",
    "\n",
    "        # Create the path of this class\n",
    "        class_path = os.path.join(dir, label)\n",
    "\n",
    "        # Get all images in this directory\n",
    "        images = os.listdir(class_path)\n",
    "\n",
    "        # Create the path of each images in this class\n",
    "        for image in images:\n",
    "            \n",
    "            # Create the path of this image\n",
    "            image_path = os.path.join(class_path, image)\n",
    "\n",
    "            # Add the image path to the image paths array\n",
    "            image_paths = np.append(image_paths, image_path)\n",
    "\n",
    "        # Add the image paths to the class paths array\n",
    "        class_paths.append(image_paths)\n",
    "        \n",
    "    return class_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(batch_size, image_paths, model):\n",
    "    \"\"\"\n",
    "    Makes predictions with the model\n",
    "        \n",
    "    batch_size: number of predictions to make\n",
    "    image_paths: paths to images\n",
    "    model: image classifier model\n",
    "    return: resulting predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    images_arr = []\n",
    "    \n",
    "    # load images     \n",
    "    for image_path in image_paths:\n",
    "        # load the image\n",
    "        image_pil = load_img(image_path, interpolation='nearest', target_size=(image_dim, image_dim, 3))\n",
    "\n",
    "        # turn it into an array\n",
    "        image_arr = img_to_array(image_pil)\n",
    "\n",
    "        # add the image_arr to the images_arr array\n",
    "        images_arr.append(image_arr)\n",
    " \n",
    "    # turn it into a numpy arrays so that it can be feed into the model as a batch\n",
    "    images = np.array(images_arr)\n",
    "    \n",
    "    # make a predictions on the batch\n",
    "    predictions = model.predict(images, batch_size=batch_size)\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_accuracy(class_keys, label, predictions):\n",
    "    \"\"\"\n",
    "    Determine the accuracy of a set of a image predictions\n",
    "    \n",
    "    class_keys: list of class keys\n",
    "    label: true class of the predictions\n",
    "    predictions: array of image predictions\n",
    "    return: average correct image predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of correct predictions\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    # number of predictions made\n",
    "    n_predictions = len(predictions)\n",
    "    \n",
    "    # check how many predictions were correct\n",
    "    for prediction in predictions:\n",
    "        # determine the most likely class from the prediction\n",
    "        most_likely_class = np.argmax(prediction)\n",
    "        \n",
    "        # get the label of the prediction\n",
    "        prediction_label = class_keys[most_likely_class]\n",
    "        \n",
    "        # check if it matches the label\n",
    "        # if so, increment the counter\n",
    "        if prediction_label == label:\n",
    "            \n",
    "            correct_predictions += 1\n",
    "            \n",
    "    # calculate the average correct of the predictions\n",
    "    average = correct_predictions / n_predictions\n",
    "    \n",
    "    return average\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True) # Reinforcements for training dataset\n",
    "\n",
    "validate = ImageDataGenerator(rescale=1./255) # Reinforcements for validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#loads the datasets\n",
    "train_dataset = train.flow_from_directory(train_dir, target_size=(image_dim, image_dim), class_mode='categorical') \n",
    "validate_dataset = train.flow_from_directory(validate_dir, target_size=(image_dim, image_dim), class_mode='categorical')\n",
    "\n",
    "# tf.keras.preprocessing.image_dataset_from_directory - this can be used for no reinforcement\n",
    "\n",
    "n_train = train_dataset.samples # number of images in training dataset\n",
    "n_validate = validate_dataset.samples # number of images in validation dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_keys = list(train_dataset.class_indices.keys())\n",
    "n_classes = len(class_keys)\n",
    "\n",
    "# defines the layers of the cnn\n",
    "model = tf.keras.models.Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(n_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current accuracy of model for class butterfly: 0.15\n",
      "Current accuracy of model for class cat: 0.0\n",
      "Current accuracy of model for class chicken: 0.0\n",
      "Current accuracy of model for class cow: 0.0\n",
      "Current accuracy of model for class dog: 0.0\n",
      "Current accuracy of model for class elephant: 0.0\n",
      "Current accuracy of model for class horse: 0.11\n",
      "Current accuracy of model for class sheep: 0.0\n",
      "Current accuracy of model for class spider: 0.635\n",
      "Current accuracy of model for class squirrel: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Finds how accurate the model is w/o training\n",
    "\n",
    "# Get the name of each directory in the root directory and store them as an array.\n",
    "classes = get_class_labels(validate_dir)\n",
    "\n",
    "# Get the paths of all the images in the first class directory and store them as a 2d array.\n",
    "image_paths = get_class_images(classes, validate_dir)\n",
    "\n",
    "for i, single_class in enumerate(class_keys):\n",
    "    # label of the class we are making predictions on\n",
    "    single_class_image_paths = image_paths[i]\n",
    "\n",
    "    single_class_predictions = predict(int(n_validate / n_classes), single_class_image_paths, model)\n",
    "\n",
    "    # get the accuracy of predictions on the first class\n",
    "    single_class_accuracy = predictions_accuracy(class_keys, single_class, single_class_predictions)\n",
    "\n",
    "    print(\"Current accuracy of model for class \" + single_class + \": \" + str(single_class_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Local\\Temp/ipykernel_13584/3456128906.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_dataset,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 22/250 [=>............................] - ETA: 3:34:51 - loss: 2.3021 - accuracy: 0.1108"
     ]
    }
   ],
   "source": [
    "log_dir = base_log_dir + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=learning_rate, momentum=0.9),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_dataset,\n",
    "                    steps_per_epoch=math.floor(n_train/batch_size),\n",
    "                    validation_data=validate_dataset,\n",
    "                    validation_steps=n_validate,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[tensorboard])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73b88dd79e00e0f4f57583c826c7adc853d853881b61c8cf34662a4ee9c223e3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
