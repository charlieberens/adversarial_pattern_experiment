{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs for new environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install tensorflow\n",
    "# !{sys.executable} -m pip install matplotlib\n",
    "# !{sys.executable} -m pip install numpy\n",
    "# !{sys.executable} -m pip install pillow\n",
    "# !{sys.executable} -m pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import math\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim = 256 # eventual width/height of images\n",
    "input_shape = (image_dim, image_dim, 3) #(width, height, RGB)\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 32\n",
    "learning_rate = .001\n",
    "\n",
    "train_dir = 'dataset/train'\n",
    "validate_dir = 'dataset/validate'\n",
    "\n",
    "save_dir = 'models/reinforced_full'\n",
    "file_name_base = 'reinforced_full'\n",
    "\n",
    "base_log_dir = '/logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True) # Reinforcements for training dataset\n",
    "\n",
    "validate = ImageDataGenerator(rescale=1./255) # Reinforcements for validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#loads the datasets\n",
    "train_dataset = train.flow_from_directory(train_dir, target_size=(image_dim, image_dim), class_mode='categorical') \n",
    "validate_dataset = train.flow_from_directory(validate_dir, target_size=(image_dim, image_dim), class_mode='categorical')\n",
    "\n",
    "# tf.keras.preprocessing.image_dataset_from_directory - this can be used for no reinforcement\n",
    "\n",
    "n_train = train_dataset.samples # number of images in training dataset\n",
    "n_validate = validate_dataset.samples # number of images in validation dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_keys = list(train_dataset.class_indices.keys())\n",
    "n_classes = len(class_keys)\n",
    "\n",
    "# defines the layers of the cnn\n",
    "model = tf.keras.models.Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(n_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = base_log_dir + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Save the initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 76s 1s/step - loss: 2.3031 - accuracy: 0.0985\n",
      "INFO:tensorflow:Assets written to: models/reinforced_full/reinforced_full_0\\assets\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(validate_dataset, batch_size=256)\n",
    "model.save(save_dir + '/' + file_name_base + '_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(save_dir + '/' + file_name_base + '_15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "250/250 [==============================] - 916s 4s/step - loss: 1.3545 - accuracy: 0.5364 - val_loss: 1.4778 - val_accuracy: 0.5000\n",
      "Epoch 2/15\n",
      "250/250 [==============================] - 927s 4s/step - loss: 1.3244 - accuracy: 0.5455 - val_loss: 1.5183 - val_accuracy: 0.4874\n",
      "Epoch 3/15\n",
      "250/250 [==============================] - 931s 4s/step - loss: 1.2877 - accuracy: 0.5577 - val_loss: 1.4621 - val_accuracy: 0.5086\n",
      "Epoch 4/15\n",
      "250/250 [==============================] - 938s 4s/step - loss: 1.2350 - accuracy: 0.5723 - val_loss: 1.4066 - val_accuracy: 0.5312\n",
      "Epoch 5/15\n",
      "250/250 [==============================] - 912s 4s/step - loss: 1.2116 - accuracy: 0.5889 - val_loss: 1.3970 - val_accuracy: 0.5277\n",
      "Epoch 6/15\n",
      "250/250 [==============================] - 926s 4s/step - loss: 1.1476 - accuracy: 0.6081 - val_loss: 1.4013 - val_accuracy: 0.5282\n",
      "Epoch 7/15\n",
      "250/250 [==============================] - 942s 4s/step - loss: 1.1058 - accuracy: 0.6290 - val_loss: 1.4179 - val_accuracy: 0.5237\n",
      "Epoch 8/15\n",
      "250/250 [==============================] - 942s 4s/step - loss: 1.0788 - accuracy: 0.6399 - val_loss: 1.3455 - val_accuracy: 0.5454\n",
      "Epoch 9/15\n",
      "250/250 [==============================] - 952s 4s/step - loss: 1.0506 - accuracy: 0.6439 - val_loss: 1.3231 - val_accuracy: 0.5585\n",
      "Epoch 10/15\n",
      "250/250 [==============================] - 957s 4s/step - loss: 1.0022 - accuracy: 0.6634 - val_loss: 1.3739 - val_accuracy: 0.5509\n",
      "Epoch 11/15\n",
      "250/250 [==============================] - 956s 4s/step - loss: 0.9826 - accuracy: 0.6675 - val_loss: 1.3438 - val_accuracy: 0.5645\n",
      "Epoch 12/15\n",
      "250/250 [==============================] - 825s 3s/step - loss: 0.9214 - accuracy: 0.6881 - val_loss: 1.3067 - val_accuracy: 0.5736\n",
      "Epoch 13/15\n",
      "250/250 [==============================] - 762s 3s/step - loss: 0.8825 - accuracy: 0.6956 - val_loss: 1.3825 - val_accuracy: 0.5539\n",
      "Epoch 14/15\n",
      "250/250 [==============================] - 748s 3s/step - loss: 0.8381 - accuracy: 0.7176 - val_loss: 1.3663 - val_accuracy: 0.5675\n",
      "Epoch 15/15\n",
      "250/250 [==============================] - 748s 3s/step - loss: 0.8179 - accuracy: 0.7215 - val_loss: 1.3374 - val_accuracy: 0.5670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bedd7103d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset,\n",
    "                    steps_per_epoch=math.floor(n_train/batch_size),\n",
    "                    validation_data=validate_dataset,\n",
    "                    validation_steps=math.floor(n_validate/batch_size),\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/reinforced_full/reinforced_full_30\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(save_dir + '/' + file_name_base + '_30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JS Baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "\n",
    "model = tf.keras.models.load_model(save_dir + '/' + file_name_base + '_30')\n",
    "tfjs.converters.save_keras_model(model,'../../app/src/models/' + file_name_base + '_30')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73b88dd79e00e0f4f57583c826c7adc853d853881b61c8cf34662a4ee9c223e3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
