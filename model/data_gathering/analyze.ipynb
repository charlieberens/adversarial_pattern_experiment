{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../animal_classifier/models/'\n",
    "models = ['augmented', 'not_augmented']\n",
    "epochs = [0,16,32,48,64]\n",
    "\n",
    "train_dir = '../animal_classifier/dataset/train'\n",
    "\n",
    "validate_dir = '../animal_classifier/dataset/validate'\n",
    "batch_size = 32\n",
    "\n",
    "example_dir = ''\n",
    "\n",
    "data_output_dir = ''\n",
    "\n",
    "epsilons = [0, .01, .1, .15]\n",
    "\n",
    "image_dim = 256 # eventual width/height of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train = tf.keras.preprocessing.image.ImageDataGenerator() # Reinforcements for training dataset\n",
    "\n",
    "validate = tf.keras.preprocessing.image.ImageDataGenerator() # Reinforcements for validation dataset\n",
    "\n",
    "#loads the datasets\n",
    "train_dataset = train.flow_from_directory(train_dir, target_size=(image_dim, image_dim), class_mode='categorical') \n",
    "validate_dataset = validate.flow_from_directory(validate_dir, target_size=(image_dim, image_dim), class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 10 classes.\n",
      "Found 2000 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir, labels='inferred')\n",
    "validate_dataset = tf.keras.preprocessing.image_dataset_from_directory(validate_dir, labels='inferred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, model):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (256,256))\n",
    "    # image = model.preprocess_input(image)\n",
    "    image = image[None, ...] #adds that goofy empty dimension\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adversarial_pattern(input_image, input_label, model):\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(input_image)\n",
    "    prediction = model(input_image)\n",
    "    loss = tf.keras.losses.MSE(input_label, prediction)\n",
    "\n",
    "  # Get the gradients of the loss w.r.t to the input image.\n",
    "  gradient = tape.gradient(loss, input_image)\n",
    "  # Get the sign of the gradients to create the perturbation\n",
    "  signed_grad = tf.sign(gradient)\n",
    "  return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../animal_classifier/dataset/validate\\butterfly\n",
      "../animal_classifier/dataset/validate\\cat\n",
      "../animal_classifier/dataset/validate\\chicken\n",
      "../animal_classifier/dataset/validate\\cow\n",
      "../animal_classifier/dataset/validate\\dog\n",
      "../animal_classifier/dataset/validate\\elephant\n",
      "../animal_classifier/dataset/validate\\horse\n",
      "../animal_classifier/dataset/validate\\sheep\n",
      "../animal_classifier/dataset/validate\\spider\n",
      "../animal_classifier/dataset/validate\\squirrel\n",
      "../animal_classifier/dataset/validate\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "classes = ['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']\n",
    "for root, dir, files in os.walk(validate_dir, topdown=False):\n",
    "    print(root)\n",
    "    if('\\\\' in root):\n",
    "        label = classes.index(root.split('\\\\')[1])\n",
    "        image_paths += ([{'label': label, 'path': root + '/' + file} for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Image transformations require SciPy. Install SciPy.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13692/1860386311.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# [loss, accuracy] = model.evaluate(validate_dataset, batch_size=batch_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m# Create adversarial dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Coding\\EE\\adversarial_pattern_experiment\\model\\venv_outer\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Coding\\EE\\adversarial_pattern_experiment\\model\\venv_outer\\lib\\site-packages\\keras_preprocessing\\image\\affine_transformations.py\u001b[0m in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \"\"\"\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m         raise ImportError('Image transformations require SciPy. '\n\u001b[0m\u001b[0;32m    282\u001b[0m                           'Install SciPy.')\n\u001b[0;32m    283\u001b[0m     \u001b[0mtransform_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Image transformations require SciPy. Install SciPy."
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    model_path = model_dir + model_name + '/' + model_name\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for epoch in epochs:\n",
    "        model = tf.keras.models.load_model(model_path + '_' + str(epoch))\n",
    "        model.trainable = False\n",
    "        # [loss, accuracy] = model.evaluate(validate_dataset, batch_size=batch_size)\n",
    "        train_accuracy = model.evaluate(train_dataset, batch_size=batch_size)[1]\n",
    "        # Create adversarial dataset\n",
    "        \n",
    "        indicies = random.sample(range(0,len(image_paths)-1),batch_size)\n",
    "        metrics = {'n': 0, 'loss_sum': 0, 'accuracy_sum': 0, 'example_loss_sum': 0, 'example_accuracy_sum': 0}\n",
    "\n",
    "        for index in indicies:\n",
    "            image_raw = tf.io.read_file(image_paths[index]['path'])\n",
    "            image = tf.image.decode_image(image_raw, channels=3)\n",
    "            label = image_paths[index]['label']\n",
    "            \n",
    "            image = preprocess(image, model)\n",
    "            image_probs = model.predict(image)[0]\n",
    "            result = np.argmax(image_probs)\n",
    "            perterbations = create_adversarial_pattern(image,label, model)\n",
    "            # plot_image = tf.image.resize(tf.cast(tf.image.decode_image(image_raw, channels=3), tf.float32) / 255, (256,256));\n",
    "            plt.figure()\n",
    "            plt.imshow(image[0] / 255)\n",
    "            plt.figure()\n",
    "            plt.imshow(perterbations[0] * 0.5 + 0.5)\n",
    "            print(perterbations[0])\n",
    "            plt.figure()\n",
    "            plt.imshow(image[0] / 255 + (perterbations[0] * 0.5 + 0.5) * .1)\n",
    "            plt.title(str(result) + '%')\n",
    "            metrics['n'] += 1\n",
    "        print(model_path + '_' + str(epoch), train_accuracy)\n",
    "\n",
    "        # [example_loss, example_accuracy] = model.evaluate(example_dataset, batch_size=batch_size)\n",
    "\n",
    "        # data.append({'epoch': epoch, 'loss': loss, 'accuracy': accuracy, 'train_accuracy': train_accuracy, 'example_loss': example_loss, 'example_accuracy': example_accuracy, 'batch_size': batch_size})\n",
    "        \n",
    "    # df = pd.DataFrame(data)\n",
    "    # print(df)\n",
    "    # df.to_csv(path_or_buf=data_output_dir)\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0172a90b0870b08d83fdf51ba1b41e53251ef35db2de7f885b685f2131977621"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
