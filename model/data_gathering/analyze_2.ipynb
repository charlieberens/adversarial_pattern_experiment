{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "from os import walk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../animal_classifier/models/'\n",
    "models = ['augmented', 'not_augmented']\n",
    "epochs = [0,16,32,48,64]\n",
    "\n",
    "train_dir = '../animal_classifier/dataset/train'\n",
    "validate_dir = '../animal_classifier/dataset/validate'\n",
    "data_output_dir = './data_output'\n",
    "\n",
    "epsilons = [0, .1, .2, .3, .4]\n",
    "sample_size = 16 # Samples per class\n",
    "image_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']\n",
    "validate_folder_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indices(): #Optional code that generates random images to use\n",
    "    index_matrix = []\n",
    "\n",
    "    for animal in classes:\n",
    "        indices = random.sample(range(validate_folder_size), sample_size)\n",
    "        index_matrix.append(indices)\n",
    "    return index_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generate_indices())\n",
    "index_matrix = [[53, 31, 107, 90, 75, 140, 85, 160, 177, 158, 68, 154, 6, 54, 8, 163], [18, 119, 160, 124, 78, 108, 110, 55, 188, 173, 82, 67, 114, 7, 40, 128], [172, 25, 109, 67, 145, 117, 143, 134, 138, 148, 10, 86, 189, 7, 166, 89], [69, 111, 67, 112, 170, 40, 146, 95, 64, 178, 17, 193, 104, 197, 21, 161], [174, 114, 170, 158, 84, 65, 173, 126, 77, 188, 194, 145, 2, 33, 182, 135], [197, 164, 105, 88, 64, 111, 3, 159, 28, 135, 80, 96, 14, 35, 173, 172], [46, 165, 199, 39, 194, 26, 153, 131, 120, 34, 172, 130, 90, 5, 157, 17], [0, 176, 73, 84, 155, 143, 119, 174, 83, 95, 132, 39, 162, 90, 100, 62], [78, 108, 8, 107, 139, 87, 29, 188, 4, 112, 51, 42, 33, 28, 93, 192], [101, 46, 15, 76, 154, 86, 112, 120, 78, 74, 68, 107, 153, 149, 80, 87]]\n",
    "#Which image indices for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates image paths\n",
    "def get_image(animal, index):\n",
    "    directory = validate_dir + '/' + animal\n",
    "    filenames = next(walk(directory), (None, None, []))[2] #Black magic that returns list of filenames in directory\n",
    "    return tf.io.read_file(directory + '/' + filenames[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perterbations(model, input_image, class_index):\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(input_image)\n",
    "    prediction = model(input_image)\n",
    "    loss = tf.keras.losses.MSE(class_index, prediction)\n",
    "\n",
    "  # Get the gradients of the loss w.r.t to the input image.\n",
    "  gradient = tape.gradient(loss, input_image)\n",
    "  # Get the sign of the gradients to create the perturbation\n",
    "  signed_grad = tf.sign(gradient)\n",
    "  return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(probs, animal_index): #Calculates MSE loss\n",
    "    total = 0\n",
    "    for index, prob in enumerate(probs):\n",
    "        if index == animal_index:\n",
    "            total += (1-prob)*(1-prob)\n",
    "        else:\n",
    "            total += prob*prob\n",
    "    return total/len(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adversarial_dataset(model):    \n",
    "    eps_all_losses = [[] for __ in epsilons] # [[]] * len(epsilons) makes a list of lists that reference eachother. Editing one affects all of them.\n",
    "    eps_losses = [0] * len(epsilons)\n",
    "    eps_accuracy = [0] * len(epsilons)\n",
    "\n",
    "    for animal_index, indices in enumerate(index_matrix):\n",
    "        animal_name = classes[animal_index]\n",
    "        \n",
    "        for index in indices:\n",
    "            # Load and process image\n",
    "            image_raw = get_image(animal_name, index)\n",
    "            image = tf.image.decode_image(image_raw, channels=3)\n",
    "            image = tf.cast(image, tf.float32)\n",
    "            image = tf.image.resize(image, (256,256))\n",
    "            image = image[None, ...] #adds that goofy empty dimension\n",
    "\n",
    "            perterbations = get_perterbations(model, image, animal_index)\n",
    "\n",
    "            # Check new predicted value for each epsilon\n",
    "            for eps_index, eps in enumerate(epsilons):\n",
    "                image_probs = model.predict(image - perterbations * eps)[0]\n",
    "\n",
    "                loss = get_loss(image_probs, animal_index)\n",
    "                eps_losses[eps_index] += loss\n",
    "                eps_all_losses[eps_index].append(loss)\n",
    "\n",
    "                # If correct guess -> add one to total\n",
    "                if image_probs[animal_index] == max(image_probs):\n",
    "                    eps_accuracy[eps_index] += 1\n",
    "\n",
    "    eps_avg_losses = [total / (len(classes) * sample_size) for total in eps_losses]\n",
    "    eps_avg_accuracy = [total / (len(classes) * sample_size) for total in eps_accuracy]\n",
    "\n",
    "    return (eps_avg_losses, eps_avg_accuracy, eps_all_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_0.csv created!\n",
      "augmented_16.csv created!\n",
      "augmented_32.csv created!\n",
      "augmented_48.csv created!\n",
      "augmented_64.csv created!\n",
      "augmented.csv created!\n",
      "not_augmented_0.csv created!\n",
      "not_augmented_16.csv created!\n",
      "not_augmented_32.csv created!\n",
      "not_augmented_48.csv created!\n",
      "not_augmented_64.csv created!\n",
      "not_augmented.csv created!\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    row_list = []\n",
    "    for epoch in epochs:\n",
    "        model = tf.keras.models.load_model(model_dir + model_name + '/' + model_name + '_' + str(epoch))\n",
    "        [avg_loss, avg_accuracy, all_losses] = create_adversarial_dataset(model)\n",
    "        row_list.append([epoch, *avg_loss, *avg_accuracy])\n",
    "        loss_df = pd.DataFrame(all_losses, index = [*[str(eps) for eps in epsilons]])\n",
    "        loss_df = loss_df.transpose()\n",
    "        loss_df.to_csv(data_output_dir + '/all_losses/' + model_name + '_' + str(epoch) + '.csv', index=False)\n",
    "        print(model_name + '_' + str(epoch) + '.csv created!')\n",
    "\n",
    "    general_df = pd.DataFrame(row_list, columns=['Epoch', *['Loss_' + str(eps) for eps in epsilons], *['Accuracy_' + str(eps) for eps in epsilons]])\n",
    "    general_df.to_csv(data_output_dir + '/general/' + model_name + '.csv', index=False)\n",
    "    print(model_name + '.csv created!')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a95b7b7613ef179d2f14c2705324a8e20b14f505a6d44395d421a0b9b3a1820"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv_outer': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
